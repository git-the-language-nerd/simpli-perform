{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import re\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOUBLE-CHECK THIS:\n",
      "out_eng_from_EW-SEW\n"
     ]
    }
   ],
   "source": [
    "INPUT_FILE_ENG = \"../1 preproc/data_preproc/data_subset_eng_5000_from_EW-SEW_08_24_18h\"\n",
    "INPUT_FILE_FRE = \"../1 preproc/data_preproc/data_subset_fre_5000_from_WiViCo2_08_31_10h\"\n",
    "INPUT_FILE_GER = \"../1 preproc/data_preproc/data_subset_ger_5000_from_DEPlain_09_11_12h\"\n",
    "\n",
    "######################\n",
    "LANGUAGE = 'eng'\n",
    "MODEL = 'ChatGPT'\n",
    "SOURCE_DATASET = 'EW-SEW'\n",
    "SIZE_OF_OUTPUT_DATASET = 1000+100\n",
    "######################\n",
    "\n",
    "output_file_name =  \"out_\" + LANGUAGE + \"_from_\" + SOURCE_DATASET\n",
    "\n",
    "print(\"DOUBLE-CHECK THIS:\")\n",
    "print(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGUAGE IS: ### eng\n",
      "input_file is:  ../1 preproc/data_preproc/data_subset_eng_5000_from_EW-SEW_08_24_18h \n",
      "____\n",
      "\n",
      "57224|Toxicofera (Greek for \"those who bear toxins\") , is a hypothetical clade which represents about 4600 species (nearly 60 %) of extant squamates (scaled lizards.)\n",
      "117533|The islands of the Caribbean Sea, collectively known as the West Indies, are sorted by size and location into the Bahamas (or Lucayan archipelago, which includes the Turks and Caicos Islands) , the Lesser Antilles, and the Greater Antilles.\n",
      "3709|Some websites do not allow typographic quotation marks or apostrophes in posts (one such example being YouTube) .\n",
      "Empty DataFrame\n",
      "Columns: [source_index, original_sent, simplified_sent]\n",
      "Index: []\n",
      "[('57224',\n",
      "  'Toxicofera (Greek for \"those who bear toxins\") , is a hypothetical clade '\n",
      "  'which represents about 4600 species (nearly 60 %) of extant squamates '\n",
      "  '(scaled lizards.)'),\n",
      " ('117533',\n",
      "  'The islands of the Caribbean Sea, collectively known as the West Indies, '\n",
      "  'are sorted by size and location into the Bahamas (or Lucayan archipelago, '\n",
      "  'which includes the Turks and Caicos Islands) , the Lesser Antilles, and the '\n",
      "  'Greater Antilles.'),\n",
      " ('3709',\n",
      "  'Some websites do not allow typographic quotation marks or apostrophes in '\n",
      "  'posts (one such example being YouTube) .'),\n",
      " ('50928',\n",
      "  'Ecological yield is the harvestable population growth of an ecosystem.'),\n",
      " ('126524',\n",
      "  \"When he was 16-years-old, Davey's mother left with him to England in 1931.\")]\n"
     ]
    }
   ],
   "source": [
    "print(\"LANGUAGE IS: ###\", LANGUAGE)\n",
    "if LANGUAGE == 'fre':\n",
    "    input_file = INPUT_FILE_FRE\n",
    "elif LANGUAGE == 'ger':\n",
    "    input_file = INPUT_FILE_GER\n",
    "elif LANGUAGE == 'eng':\n",
    "    input_file = INPUT_FILE_ENG\n",
    "print(\"input_file is: \", input_file, \"\\n____\\n\")\n",
    "\n",
    "\n",
    "with open(input_file) as file:\n",
    "    lines = [line.strip() for line in file.readlines() if line.strip() != \"\"]\n",
    "\n",
    "    for line in lines[:3]:\n",
    "        print(line)\n",
    "\n",
    "tuples_list = [(line.split(\"|\")[0], line.split(\"|\")[1].strip()) for line in lines]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"source_index\", \"original_sent\", \"simplified_sent\"])\n",
    "print(df)\n",
    "\n",
    "pprint(tuples_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn each of these 50 unrelated sentences into simple language, while retaining all of the most important information from the original. Simple language is characterized by simple sentence structures and simple words. Answer by giving only the simplified sentences, no numbering, no other remarks.\n",
      "ORIGINAL SENTENCES : \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts_eng = [\n",
    "    \"Simplify this sentence: \",\n",
    "    \"Simplify this sentence, return only the simplified sentence: \",\n",
    "    \"Simplify the following new complex sentence. Here's an example: Complex: Hitherto, smoking was prohibited in the facilities. Simple: Smoking was forbidden here until now. New complex sentence: \",\n",
    "    \"Rewrite the following sentence to be as simple and concise as possible, while keeping all the essential information intact: \",\n",
    "    \"Make this sentence easier to understand: \",\n",
    "    \"Simplify this original sentence. The result should be a sentence with a easy sentence structure and should include only easy words. Original sentence: \",\n",
    "    \"Simplify this original sentence by creating an alternative version with a simpler sentence structure and fewer difficult words. Original sentence: \",\n",
    "    \"Make an alternative version of this original sentence which is shorter, exhibits a simpler structure and easier words.  For example, \\\"Hitherto, smoking was prohibited in the facilities.\\\"  could become \\\"Smoking was forbidden here until now.\\\". Original sentence: \",\n",
    "    \"Explain the following to a five year old: \",\n",
    "    \"Simplify this original sentence. Change it as much as possible without altering the meaning. Return only the simplified sentence. Original Sentence: \",\n",
    "    \"\"\"Simplify each of these 50 unrelated sentences one by one. Return only the simplified sentences, no numbering, no comments or explanations.\n",
    "ORIGINAL SENTENCES : \\n\\n\"\"\",\n",
    "    \"\"\"Turn each of these 50 unrelated sentences into simple language, while retaining all of the most important information from the original. Simple language is characterized by simple sentence structures and simple words. Answer by giving only the simplified sentences, no numbering, no other remarks.\n",
    "ORIGINAL SENTENCES : \\n\\n\"\"\"\n",
    "]\n",
    "\n",
    "prompts_ger = [\n",
    "    \"\"\"Verwandle jeden dieser 50 nicht zusammenhängenden Originalsätze einzeln in einfache Sprache. Behalte dabei die wichtigsten Informationen aus dem jeweiligen Originalsatz bei. Einfache Sprache ist durch einfache Satzstrukturen und leichte Wörter gekennzeichnet. Antworte, indem du nur die vereinfachten Sätze auflistest, ohne Nummerierung und ohne sonstige Hinweise.\n",
    "ORIGINALSÄTZE : \\n\\n\"\"\"\n",
    "\n",
    "]\n",
    "\n",
    "prompts_fre = [\n",
    "    \"\"\"Convertis chacune de ces 50 phrases originales non liées en langage simple, une par une. Conserve les informations les plus importantes de la phrase originale. Le langage simple se caractérise par des structures de phrases simples et l'utilisage des mots faciles. Réponds en énumérant uniquement les phrases simplifiées, sans numérotation ni autres remarques.\n",
    "PHRASES ORIGINALES : \\n\\n\"\"\"\n",
    "\n",
    "]\n",
    "\n",
    "if LANGUAGE == 'fre':\n",
    "    prompts = prompts_fre\n",
    "elif LANGUAGE == 'ger':\n",
    "    prompts = prompts_ger\n",
    "elif LANGUAGE == 'eng':\n",
    "    prompts = prompts_eng\n",
    "\n",
    "instruction_prompt_used = prompts[-1]\n",
    "print(instruction_prompt_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_into_list_of_sents(input_text):\n",
    "    # Split the input by line breaks\n",
    "    \n",
    "    if '\\n' in input_text:\n",
    "        sentences = input_text.splitlines()\n",
    "    else:\n",
    "        sentences = re.split(r'(?<!\\b\\w\\.\\w)(?<!\\d\\.\\d)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s', input_text)\n",
    "\n",
    "    # Initialize a list to hold the cleaned sentences\n",
    "    cleaned_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Remove leading/trailing whitespaces\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        # Remove bullet points, numbers, and any special characters\n",
    "        sentence = re.sub(r'^[\\d\\.\\-\\•\\•]+\\s*', '', sentence)  # Matches numbers, bullets, etc.\n",
    "\n",
    "        # Only append non-empty sentences\n",
    "        if sentence:\n",
    "            cleaned_sentences.append(sentence)\n",
    "\n",
    "    return cleaned_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchwise_inference(input_list, dataframe, batch_size=50):\n",
    "\n",
    "    output_list = []  # Initialize the output list\n",
    "\n",
    "    # Iterate over input_list in chunks of batch_size\n",
    "    for i in range(0, len(input_list), batch_size):\n",
    "\n",
    "        batch_number = round(i/batch_size)\n",
    "\n",
    "        if i >= SIZE_OF_OUTPUT_DATASET:\n",
    "            print(\"i is \", i, \"--> Size of output dataset reached. Execution is finished.\")\n",
    "            break\n",
    "\n",
    "        #clear_output(wait=True)            \n",
    "\n",
    "        # Take a batch of 50 elements\n",
    "        input_batch = input_list[i:i + batch_size]\n",
    "        output_batch = []\n",
    "\n",
    "        #print(\"______ INPUT batch \", str(batch_number), \" ______\")\n",
    "        print(instruction_prompt_used)\n",
    "        # 1. Print each element in the batch separated by line breaks\n",
    "        for element in input_batch:\n",
    "            print(element[-1]+\"\\n\")\n",
    "        \n",
    "        # 2. Print separator \"_____\"\n",
    "        print(\"_____\\n\\n\")\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # 3. Wait for user input\n",
    "            model_output = input(str(\"Enter input for batch number, \" + str(batch_number) +\": \"))\n",
    "            # 4. Call my_function with user input and extend the result to output_list\n",
    "            processed_output = process_text_into_list_of_sents(model_output)\n",
    "\n",
    "\n",
    "            if len(processed_output) != batch_size:\n",
    "                print(\"Input invalid. Enter input correctly.\")\n",
    "                print(\"Len of proc'ed output: \", len(processed_output))\n",
    "                for s in processed_output:\n",
    "                    print(s, \"\\n\")\n",
    "            else:\n",
    "                # If result is valid, break the loop and extend the output list\n",
    "                output_list.extend(processed_output)\n",
    "                output_batch.extend(processed_output)\n",
    "                break\n",
    "        \n",
    "\n",
    "        print(\"______MODEL OUTPUT:______\")\n",
    "        for sent in processed_output:\n",
    "            print(sent, \"\\n\")\n",
    "\n",
    "            \n",
    "        for i, elem in enumerate(input_batch):\n",
    "            triple=[elem[0], elem[1], output_batch[i]]\n",
    "            dataframe.loc[len(dataframe)] = triple\n",
    "\n",
    "    return output_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchwise_inference_simple(input_list, dataframe,  batch_size=50):\n",
    "    # Iterate over input_list in chunks of batch_size\n",
    "    for i in range(0, len(input_list), batch_size):\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        batch_number = round(i/batch_size)\n",
    "\n",
    "        if i >= SIZE_OF_OUTPUT_DATASET:\n",
    "            print(\"i is \", i, \"--> Size of output dataset reached. Execution is finished.\")\n",
    "            break\n",
    "\n",
    "        input_batch = input_list[i:i + batch_size]\n",
    "\n",
    "        print(instruction_prompt_used)\n",
    "\n",
    "        _ = input(str(\"Press enter to get sentences\"))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for element in input_batch:\n",
    "            print(element[-1]+\"\\n\")\n",
    "\n",
    "\n",
    "    return None\n",
    "        \n",
    "#batchwise_inference_simple(tuples_list, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in tuples_list[:SIZE_OF_OUTPUT_DATASET]:\n",
    "            print(element[0]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn each of these 50 unrelated sentences into simple language, while retaining all of the most important information from the original. Simple language is characterized by simple sentence structures and simple words. Answer by giving only the simplified sentences, no numbering, no other remarks.\n",
      "ORIGINAL SENTENCES : \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instruction_prompt_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_index = 'reset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the end of the list. No more elements to display.\n"
     ]
    }
   ],
   "source": [
    "if 'current_index' not in globals() or current_index == \"reset\":\n",
    "    current_index = 0  # This will be reset to 0 when the code runs for the first time\n",
    "\n",
    "# Define the batch size (50 elements at a time)\n",
    "batch_size = 50\n",
    "\n",
    "# Check if the current_index exceeds z (the length of the list or the end limit)\n",
    "if current_index >= SIZE_OF_OUTPUT_DATASET:\n",
    "    print(\"Reached the end of the list. No more elements to display.\")\n",
    "else:\n",
    "    # Get the elements for the current batch and print them\n",
    "\n",
    "    print(instruction_prompt_used)\n",
    "\n",
    "    for element in tuples_list[current_index:current_index + batch_size]:\n",
    "        print(element[-1] + \"\\n\")\n",
    "    \n",
    "    # Update the current index for the next batch\n",
    "    current_index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m99\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\RobNLP1\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\RobNLP1\\lib\\site-packages\\pandas\\core\\indexing.py:1625\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1625\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\RobNLP1\\lib\\site-packages\\pandas\\core\\indexing.py:1557\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df.loc[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f02fefb90947aa940621ab0daff286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RobNLP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
